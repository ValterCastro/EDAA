{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./input/spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['label', 'text']\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert 'ham' to 0 and 'spam' to 1\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])  # ham=0, spam=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in stop_words]\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(w) for w in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Create cleaned version\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_raw = df['text']\n",
    "X_clean = df['clean_text']\n",
    "y = df['label']\n",
    "\n",
    "# Split both raw and clean\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42)\n",
    "X_train_clean, X_test_clean, _, _ = train_test_split(X_clean, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize vectorizers\n",
    "bow_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# --- Bag of Words ---\n",
    "X_train_bow_raw = bow_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_bow_raw = bow_vectorizer.transform(X_test_raw)\n",
    "\n",
    "# Check number of features\n",
    "n_features_train = X_train_bow_raw.shape\n",
    "n_features_test = X_test_bow_raw.shape\n",
    "print(\"Number of samples/features:\", n_features_train)\n",
    "print(\"Number of samples/features:\", n_features_test)\n",
    "\n",
    "X_train_bow_clean = bow_vectorizer.fit_transform(X_train_clean)\n",
    "X_test_bow_clean = bow_vectorizer.transform(X_test_clean)\n",
    "\n",
    "# --- TF-IDF ---\n",
    "X_train_tfidf_raw = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_tfidf_raw = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "X_train_tfidf_clean = tfidf_vectorizer.fit_transform(X_train_clean)\n",
    "X_test_tfidf_clean = tfidf_vectorizer.transform(X_test_clean)\n",
    "\n",
    "\n",
    "k = 1500  # Select top 1500 features (reduced from 1500 for efficiency)\n",
    "selector = SelectKBest(chi2, k=k)\n",
    "X_train_selected_raw = selector.fit_transform(X_train_tfidf_raw, y_train)  # Use TF-IDF matrix\n",
    "X_test_selected_raw = selector.transform(X_test_tfidf_raw)\n",
    "print(\"\\nAfter Chi-Squared Selection:\")\n",
    "print(\"X_train_selected shape:\", X_train_selected_raw.shape)\n",
    "print(\"X_test_selected shape:\", X_test_selected_raw.shape)\n",
    "\n",
    "# Step 2: Feature Transformation with PCA\n",
    "n_components = 20  # Reduce to 20 dimensions\n",
    "pca_raw = PCA(n_components=n_components)\n",
    "X_train_reduced_raw = pca_raw.fit_transform(X_train_selected_raw.toarray())  # Convert to dense\n",
    "X_test_reduced_raw = pca_raw.transform(X_test_selected_raw.toarray())\n",
    "print(\"\\nAfter PCA:\")\n",
    "print(\"X_train_reduced shape:\", X_train_reduced_raw.shape)\n",
    "print(\"X_test_reduced shape:\", X_test_reduced_raw.shape)\n",
    "\n",
    "k = 1500  # Select top 1500 features (reduced from 1500 for efficiency)\n",
    "selector = SelectKBest(chi2, k=k)\n",
    "X_train_selected_clean = selector.fit_transform(X_train_tfidf_clean, y_train)  # Use TF-IDF matrix\n",
    "X_test_selected_clean = selector.transform(X_test_tfidf_clean)\n",
    "print(\"\\nAfter Chi-Squared Selection:\")\n",
    "print(\"X_train_selected shape:\", X_train_selected_clean.shape)\n",
    "print(\"X_test_selected shape:\", X_test_selected_clean.shape)\n",
    "\n",
    "# Step 2: Feature Transformation with PCA\n",
    "n_components = 20  # Reduce to 20 dimensions\n",
    "pca_clean = PCA(n_components=n_components)\n",
    "X_train_reduced_clean = pca_clean.fit_transform(X_train_selected_clean.toarray())  # Convert to dense\n",
    "X_test_reduced_clean = pca_clean.transform(X_test_selected_clean.toarray())\n",
    "print(\"\\nAfter PCA:\")\n",
    "print(\"X_train_reduced shape:\", X_train_reduced_clean.shape)\n",
    "print(\"X_test_reduced shape:\", X_test_reduced_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def train_models(X_train, X_test, y_train, y_test, label=\"\"):\n",
    "    print(f\"\\n--- {label} ---\")\n",
    "    \n",
    "    start_time_bayes = time.time()\n",
    "    # Naive Bayes\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    pred_nb = nb.predict(X_test)\n",
    "    end_time_bayes = time.time()\n",
    "    execution_time_bayes = end_time_bayes - start_time_bayes\n",
    "    print(\"\\nNaive Bayes:\")\n",
    "    print(classification_report(y_test, pred_nb))\n",
    "    \n",
    "    \n",
    "    start_time_brute = time.time()\n",
    "    \n",
    "    # Add KNN\n",
    "    #knn = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_knn = knn.predict(X_test)\n",
    "    end_time_brute = time.time()\n",
    "    execution_time_brute = end_time_brute - start_time_brute\n",
    "    print(\"\\nK-Nearest Neighbors:\")\n",
    "    print(classification_report(y_test, pred_knn))\n",
    "    \n",
    "    \n",
    "    # KNN with k-d tree\n",
    "    start_time_kd = time.time()\n",
    "    kd = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "    kd.fit(X_train.toarray(), y_train)\n",
    "    pred_kd = kd.predict(X_test.toarray())\n",
    "    end_time_kd = time.time()\n",
    "    execution_time_kd = end_time_kd - start_time_kd\n",
    "    print(\"\\nK-Nearest Neighbors with k-d Tree:\")\n",
    "    print(classification_report(y_test, pred_kd))\n",
    "    \n",
    "        # Calculate the difference in execution times\n",
    "    time_difference = execution_time_kd - execution_time_brute\n",
    "    time_difference_bd = execution_time_kd - execution_time_bayes\n",
    "    time_difference_bb = execution_time_brute - execution_time_bayes\n",
    "\n",
    "    # Print the execution times and their difference\n",
    "    print(f\"Execution Time (Brute Force): {execution_time_brute:.6f} seconds\")\n",
    "    print(f\"Execution Time (KD Tree): {execution_time_kd:.6f} seconds\")\n",
    "    print(f\"Execution Time (Bayes): {execution_time_bayes:.6f} seconds\")\n",
    "    print(f\"Difference (KD Tree - Brute Force): {time_difference:.6f} seconds\")\n",
    "    print(f\"Difference (KD Tree - Bayes): {time_difference_bd:.6f} seconds\")\n",
    "    print(f\"Difference (Bayes - Brute Force): {time_difference_bb:.6f} seconds\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models_reduced(X_train, X_test, y_train, y_test, label=\"\"):\n",
    "  \n",
    "  \n",
    "  \n",
    "    print(f\"\\n--- {label} ---\")\n",
    "    start_time_brute = time.time()\n",
    "    \n",
    "    # Add KNN\n",
    "    #knn = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_knn = knn.predict(X_test)\n",
    "    end_time_brute = time.time()\n",
    "    execution_time_brute = end_time_brute - start_time_brute\n",
    "    print(\"\\nK-Nearest Neighbors:\")\n",
    "    print(classification_report(y_test, pred_knn))\n",
    "    \n",
    "    # # Print classification reports\n",
    "    # print(\"\\nk-d Tree Classification Report:\")\n",
    "    # print(classification_report(y_test, pred_knn, zero_division=0))\n",
    "    \n",
    "    # KNN with k-d tree\n",
    "    start_time_kd = time.time()\n",
    "    kd = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "    kd.fit(X_train, y_train)\n",
    "    pred_kd = kd.predict(X_test)\n",
    "    end_time_kd = time.time()\n",
    "    execution_time_kd = end_time_kd - start_time_kd\n",
    "    print(\"\\nK-Nearest Neighbors with k-d Tree:\")\n",
    "    print(classification_report(y_test, pred_kd))\n",
    "    \n",
    "        # Calculate the difference in execution times\n",
    "    time_difference = execution_time_kd - execution_time_brute\n",
    "    \n",
    "    \n",
    "    # print(\"\\nBrute Force Classification Report:\")\n",
    "    # print(classification_report(y_test, pred_kd, zero_division=0))\n",
    "    \n",
    "      # Print the execution times and their difference\n",
    "    print(f\"Execution Time (Brute Force): {execution_time_brute:.6f} seconds\")\n",
    "    print(f\"Execution Time (KD Tree): {execution_time_kd:.6f} seconds\")\n",
    "    print(f\"Difference (KD Tree - Brute Force): {time_difference:.6f} seconds\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW + Raw\n",
    "train_models(X_train_bow_raw, X_test_bow_raw, y_train, y_test, label=\"BoW + Raw\")\n",
    "\n",
    "# BoW + Clean\n",
    "train_models(X_train_bow_clean, X_test_bow_clean, y_train, y_test, label=\"BoW + Clean\")\n",
    "\n",
    "# TF-IDF + Raw\n",
    "train_models(X_train_tfidf_raw, X_test_tfidf_raw, y_train, y_test, label=\"TF-IDF + Raw\")\n",
    "\n",
    "# TF-IDF + Clean\n",
    "train_models(X_train_tfidf_clean, X_test_tfidf_clean, y_train, y_test, label=\"TF-IDF + Clean\")\n",
    "\n",
    "#  TF-IDF + Raw for best 20 fts\n",
    "train_models_reduced(X_train_reduced_raw, X_test_reduced_raw, y_train, y_test, label=\"TF-IDF Reduced Raw\")\n",
    "\n",
    "#  TF-IDF + Clean for best 20 fts\n",
    "train_models_reduced(X_train_reduced_clean, X_test_reduced_clean, y_train, y_test, label=\"TF-IDF Reduced Clean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def plot_knn_accuracy(X_train, X_test, y_train, y_test, k_values, label=\"\"):\n",
    "    accuracies = []\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, accuracies, marker='o')\n",
    "    plt.title(f'kNN Accuracy vs. Number of Neighbors ({label})')\n",
    "    plt.xlabel('Number of Neighbors (k)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Define the range of k values from 2 to 20\n",
    "k_values = range(2, 21)\n",
    "\n",
    "# Generate plot for TF-IDF Reduced Clean\n",
    "plot_knn_accuracy(X_train_reduced_clean, X_test_reduced_clean, y_train, y_test, k_values, label=\"TF-IDF Reduced Clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define range of PCA components to test\n",
    "n_components_list = range(10, 61)\n",
    "times_brute = []\n",
    "times_kd = []\n",
    "\n",
    "# Loop over different numbers of PCA components\n",
    "for n_components in n_components_list:\n",
    "    print(f\"Processing n_components = {n_components}\")\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_selected_clean.toarray())\n",
    "    X_test_pca = pca.transform(X_test_selected_clean.toarray())\n",
    "    \n",
    "    # kNN with Brute Force\n",
    "    knn_brute = KNeighborsClassifier(n_neighbors=5, algorithm='brute')\n",
    "    start_time = time.time()\n",
    "    knn_brute.fit(X_train_pca, y_train)\n",
    "    pred_brute = knn_brute.predict(X_test_pca)\n",
    "    end_time = time.time()\n",
    "    time_brute = end_time - start_time\n",
    "    times_brute.append(time_brute)\n",
    "    \n",
    "    # kNN with KD-Tree\n",
    "    knn_kd = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "    start_time = time.time()\n",
    "    knn_kd.fit(X_train_pca, y_train)\n",
    "    pred_kd = knn_kd.predict(X_test_pca)\n",
    "    end_time = time.time()\n",
    "    time_kd = end_time - start_time\n",
    "    times_kd.append(time_kd)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components_list, times_brute, label='Brute Force', marker='o')\n",
    "plt.plot(n_components_list, times_kd, label='KD-Tree', marker='o')\n",
    "plt.xlabel('Number of Features (PCA Components)')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Execution Time vs. Number of Features for kNN')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert sparse matrices to dense (assuming X_train_selected_clean and X_test_selected_clean are sparse)\n",
    "X_train_dense = X_train_selected_clean.toarray()\n",
    "X_test_dense = X_test_selected_clean.toarray()\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train_dense)\n",
    "X_test_std = scaler.transform(X_test_dense)\n",
    "\n",
    "# Define the range of PCA components\n",
    "n_components_list = range(2, 26)\n",
    "accuracies = []\n",
    "\n",
    "# Loop over number of PCA components\n",
    "for n in n_components_list:\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    X_train_pca = pca.fit_transform(X_train_std)\n",
    "    X_test_pca = pca.transform(X_test_std)\n",
    "    \n",
    "    # Train k-NN with KD-tree\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "    knn.fit(X_train_pca, y_train)\n",
    "    pred = knn.predict(X_test_pca)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    accuracies.append(acc)\n",
    "    print(f'n_components={n}, accuracy={acc:.4f}')\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components_list, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Accuracy vs. Number of PCA Components for k-NN with KD-Tree')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
